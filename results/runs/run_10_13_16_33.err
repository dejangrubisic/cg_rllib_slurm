2022-10-13 16:41:59,028	INFO services.py:1338 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8265[39m[22m
/private/home/dejang/.conda/envs/compiler_gym/lib/python3.8/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory
  warn(f"Failed to load image Python extension: {e}")
WARNING:compiler_gym.datasets.tar_dataset:Installing the benchmark://chstone-v0 dataset. This may take a few moments ...
INFO:ray.worker:Using address auto set in the environment variable RAY_ADDRESS
2022-10-13 16:42:31,854	INFO worker.py:842 -- Connecting to existing Ray cluster at address: 100.97.70.203:6888
[2022-10-13 16:42:31,866 I 1998824 1998824] logging.cc:191: Set ray log level from environment variable RAY_BACKEND_LOG_LEVEL to -1
[2m[36m(PPO pid=1999580)[0m 2022-10-13 16:42:40,981	INFO trainer.py:722 -- Your framework setting is 'tf', meaning you are using static-graph mode. Set framework='tf2' to enable eager execution with tf2.x. You may also want to then set `eager_tracing=True` in order to reach similar execution speed as with static-graph mode.
[2m[36m(PPO pid=1999580)[0m 2022-10-13 16:42:40,982	INFO ppo.py:166 -- In multi-agent mode, policies will be optimized sequentially by the multi-GPU optimizer. Consider setting simple_optimizer=True if this doesn't work for you.
[2m[36m(PPO pid=1999580)[0m 2022-10-13 16:42:40,982	INFO trainer.py:743 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(RolloutWorker pid=1999579)[0m 2022-10-13 16:42:48,813	WARNING deprecation.py:45 -- DeprecationWarning: `SampleBatch['is_training']` has been deprecated. Use `SampleBatch.is_training` instead. This will raise an error in the future!
[2m[36m(PPO pid=1999580)[0m 2022-10-13 16:42:50,105	WARNING deprecation.py:45 -- DeprecationWarning: `SampleBatch['is_training']` has been deprecated. Use `SampleBatch.is_training` instead. This will raise an error in the future!
[2m[36m(PPO pid=1999580)[0m 2022-10-13 16:42:50,767	INFO trainable.py:124 -- Trainable.setup took 10.514 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(PPO pid=1999580)[0m 2022-10-13 16:42:50,768	WARNING util.py:57 -- Install gputil for GPU system monitoring.
2022-10-13 16:43:58,300	INFO tune.py:626 -- Total run time: 86.26 seconds (84.15 seconds for the tuning loop).
2022-10-13 16:43:58,344	WARNING experiment_analysis.py:510 -- Could not find best trial. Did you pass the correct `metric` parameter?
